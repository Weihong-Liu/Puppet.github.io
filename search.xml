<?xml version="1.0" encoding="utf-8"?>
<search>
    
  
    
    <entry>
        <title>「Task 4」Pytorch训练得到的模型预测图像、视频、摄像</title>
        <link href="/posts/fe6a595b.html" />
        <url>/posts/fe6a595b.html</url>
        
        <content type="html">
            <![CDATA[<h1 id="1、环境配置"><a href="#1、环境配置" class="headerlink" title="1、环境配置"></a>1、环境配置</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#库安装</span></span><br><span class="line">!pip install numpy pandas matplotlib requests tqdm opencv-python pillow -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line"></span><br><span class="line"><span class="comment">#pytorch安装</span></span><br><span class="line">!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113</span><br><span class="line"></span><br><span class="line"><span class="comment">#安装mmcv -full</span></span><br><span class="line">!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu113/torch1<span class="number">.10</span><span class="number">.0</span>/index.html</span><br><span class="line"></span><br><span class="line"><span class="comment">#下载中文字体</span></span><br><span class="line">!wget https://zihao-openmmlab.obs.cn-east-<span class="number">3.</span>myhuaweicloud.com/<span class="number">20220716</span>-mmclassification/dataset/SimHei.ttf</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="2、数据准备"><a href="#2、数据准备" class="headerlink" title="2、数据准备"></a>2、数据准备</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment"># 存放测试图片</span></span><br><span class="line">os.mkdir(<span class="string">&#x27;test_img&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 存放结果文件</span></span><br><span class="line">os.mkdir(<span class="string">&#x27;output&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 存放训练得到的模型权重</span></span><br><span class="line">os.mkdir(<span class="string">&#x27;checkpoints&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载样例模型文件</span></span><br><span class="line">!wget https://zihao-openmmlab.obs.cn-east-<span class="number">3.</span>myhuaweicloud.com/<span class="number">20220716</span>-mmclassification/checkpoints/fruit30_pytorch_20220814.pth -P checkpoints</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载 类别名称 和 ID索引号 的映射字典</span></span><br><span class="line">!wget https://zihao-openmmlab.obs.cn-east-<span class="number">3.</span>myhuaweicloud.com/<span class="number">20220716</span>-mmclassification/dataset/fruit30/idx_to_labels.npy</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载测试图像文件 至 test_img 文件夹</span></span><br><span class="line"></span><br><span class="line">!wget https://zihao-openmmlab.obs.myhuaweicloud.com/<span class="number">20220716</span>-mmclassification/test/0818/test_fruits.jpg -P test_img</span><br><span class="line"></span><br><span class="line">!wget https://zihao-openmmlab.obs.myhuaweicloud.com/<span class="number">20220716</span>-mmclassification/test/0818/test_orange_2.jpg -P test_img </span><br><span class="line"></span><br><span class="line">!wget https://zihao-openmmlab.obs.myhuaweicloud.com/<span class="number">20220716</span>-mmclassification/test/0818/test_bananan.jpg -P test_img</span><br><span class="line"></span><br><span class="line">!wget https://zihao-openmmlab.obs.myhuaweicloud.com/<span class="number">20220716</span>-mmclassification/test/0818/test_kiwi.jpg -P test_img</span><br><span class="line"></span><br><span class="line">!wget https://zihao-openmmlab.obs.myhuaweicloud.com/<span class="number">20220716</span>-mmclassification/test/0818/test_石榴.jpg -P test_img</span><br><span class="line"></span><br><span class="line">!wget https://zihao-openmmlab.obs.myhuaweicloud.com/<span class="number">20220716</span>-mmclassification/test/0818/test_orange.jpg -P test_img</span><br><span class="line"></span><br><span class="line">!wget https://zihao-openmmlab.obs.myhuaweicloud.com/<span class="number">20220716</span>-mmclassification/test/0818/test_lemon.jpg -P test_img</span><br><span class="line"></span><br><span class="line">!wget https://zihao-openmmlab.obs.myhuaweicloud.com/<span class="number">20220716</span>-mmclassification/test/0818/test_火龙果.jpg -P test_img</span><br><span class="line"></span><br><span class="line">!wget https://zihao-openmmlab.obs.cn-east-<span class="number">3.</span>myhuaweicloud.com/<span class="number">20220716</span>-mmclassification/test/watermelon1.jpg -P test_img</span><br><span class="line"></span><br><span class="line">!wget https://zihao-openmmlab.obs.cn-east-<span class="number">3.</span>myhuaweicloud.com/<span class="number">20220716</span>-mmclassification/test/banana1.jpg -P test_img</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载测试视频文件 至 test_img 文件夹</span></span><br><span class="line"></span><br><span class="line">!wget https://zihao-openmmlab.obs.myhuaweicloud.com/<span class="number">20220716</span>-mmclassification/test/0818/fruits_video.mp4 -P test_img </span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="3、实验结果"><a href="#3、实验结果" class="headerlink" title="3、实验结果"></a>3、实验结果</h1><p><img src="https://imgse.com/i/pSNRD41" alt="预测结果"></p>]]>
        </content>
        
      
        <categories>
            
            <category> Pytorch预训练图像分类模型识别预测 </category>
            
        </categories>
        
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 图像分类 </tag>
            
            <tag> CV </tag>
            
        </tags>
        
    </entry>
    
    
    
    <entry>
        <title>「Task 3」Pytorch迁移学习训练自己的图像分类模型</title>
        <link href="/posts/31b35529.html" />
        <url>/posts/31b35529.html</url>
        
        <content type="html">
            <![CDATA[<h1 id="什么是迁移学习？"><a href="#什么是迁移学习？" class="headerlink" title="什么是迁移学习？"></a>什么是迁移学习？</h1><p>迁移学习是一种机器学习的方法，指的是一个预训练的模型被重新用在另一个任务中。</p><h2 id="选择迁移学习的训练方式"><a href="#选择迁移学习的训练方式" class="headerlink" title="选择迁移学习的训练方式"></a>选择迁移学习的训练方式</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#选择一：只微调训练模型最后一层（全连接分类层）</span></span><br><span class="line">model = models.resnet18(pretrained=<span class="literal">True</span>) <span class="comment"># 载入预训练模型</span></span><br><span class="line"><span class="comment"># 修改全连接层，使得全连接层的输出与当前数据集类别数对应</span></span><br><span class="line"><span class="comment"># 新建的层默认 requires_grad=True</span></span><br><span class="line">model.fc = nn.Linear(model.fc.in_features, n_class)</span><br><span class="line"><span class="comment"># 只微调训练最后一层全连接层的参数，其它层冻结</span></span><br><span class="line">optimizer = optim.Adam(model.fc.parameters())</span><br><span class="line"></span><br><span class="line"><span class="comment">#选择二：微调训练所有层</span></span><br><span class="line">model = models.resnet18(pretrained=<span class="literal">True</span>) <span class="comment"># 载入预训练模型</span></span><br><span class="line">model.fc = nn.Linear(model.fc.in_features, n_class)</span><br><span class="line">optimizer = optim.Adam(model.parameters())</span><br><span class="line"></span><br><span class="line"><span class="comment">#选择三：随机初始化模型全部权重，从头训练所有层</span></span><br><span class="line">model = models.resnet18(pretrained=<span class="literal">False</span>) <span class="comment"># 只载入模型结构，不载入预训练权重参数</span></span><br><span class="line">model.fc = nn.Linear(model.fc.in_features, n_class)</span><br><span class="line">optimizer = optim.Adam(model.parameters())</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="连接wandb进行可视化训练日志"><a href="#连接wandb进行可视化训练日志" class="headerlink" title="连接wandb进行可视化训练日志"></a>连接wandb进行可视化训练日志</h1><p><a href="https://wandb.ai/">wandb官网</a><br>登录wandb<br>1.安装 wandb：pip install wandb<br>2.登录 wandb：在命令行中运行wandb login<br>3.按提示复制粘贴API Key至命令行中</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>GitHub:<a href="https://github.com/TommyZihao/Train_Custom_Dataset">【子豪兄带你两天搞定AI毕业设计】</a><br>Bilibili:<a href="https://www.bilibili.com/video/BV1Jd4y1T7rw/?share_source=copy_web&vd_source=93b3233fa28ea39af3e78e2dcf5409c8">构建自己的图像分类数据集【两天搞定AI毕设】</a></p>]]>
        </content>
        
      
        <categories>
            
            <category> Pytorch预训练图像分类模型识别预测 </category>
            
        </categories>
        
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 图像分类 </tag>
            
            <tag> CV </tag>
            
        </tags>
        
    </entry>
    
    
    
    <entry>
        <title>「Task 2」Pytorch预训练图像分类模型预测</title>
        <link href="/posts/f3a840ed.html" />
        <url>/posts/f3a840ed.html</url>
        
        <content type="html">
            <![CDATA[<h1 id="1、提出一个问题：我们在做深度学习时为什么要使用预训练模型？"><a href="#1、提出一个问题：我们在做深度学习时为什么要使用预训练模型？" class="headerlink" title="1、提出一个问题：我们在做深度学习时为什么要使用预训练模型？"></a>1、提出一个问题：我们在做深度学习时为什么要使用预训练模型？</h1><p>当然是因为自己从头训练（所有权重随机初始化）太费时费力了<br>当我们用卷积神经网络训练自己的数据得到图片分类器时，会发现网络大多数结构包括convolution layers， pooling layers等是用来提取图片特征的，在这些layers的开始部分，提取的特征是相当泛化的，比如说边缘特征、色块特征。越到后面的layers，提取的特征越具有特殊性，例如ImageNet 数据集包含了许多不同品种的狗，到后面的layers便具备了狗的一些共有特征。<br>因此我们通常会将别人训练过的模型拿来用（用这些模型的权重来初始化），通常有两种用法。第一，前面的layers全部保留，只训练最后的分类器（SVM，Softmax等），以使用caffe为例，具体做法就是修改train的prototxt文件里面最后一个fc层的名字和输出数。第二，保留一部分layers（当然也可以不保留），然后重新训练（此时有back propagation的过程而第一没有）。</p><h1 id="2、Pytorch预训练模型有哪些"><a href="#2、Pytorch预训练模型有哪些" class="headerlink" title="2、Pytorch预训练模型有哪些"></a>2、Pytorch预训练模型有哪些</h1><p>VGG16、VGG19、densenet、ResNet、mobilenet</p><h1 id="3、使用ImageNet预训练图像分类模型预测单张图像"><a href="#3、使用ImageNet预训练图像分类模型预测单张图像" class="headerlink" title="3、使用ImageNet预训练图像分类模型预测单张图像"></a>3、使用ImageNet预训练图像分类模型预测单张图像</h1><h2 id="3-1、载入预训练图像分类模型"><a href="#3-1、载入预训练图像分类模型" class="headerlink" title="3.1、载入预训练图像分类模型"></a>3.1、载入预训练图像分类模型</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> models</span><br><span class="line"></span><br><span class="line"><span class="comment"># 载入预训练图像分类模型</span></span><br><span class="line">model = models.resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># model = models.resnet152(pretrained=True)</span></span><br><span class="line"></span><br><span class="line">model = model.<span class="built_in">eval</span>()</span><br><span class="line">model = model.to(device)</span><br></pre></td></tr></table></figure><h2 id="3-2、图像预处理"><a href="#3-2、图像预处理" class="headerlink" title="3.2、图像预处理"></a>3.2、图像预处理</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="comment"># 测试集图像预处理-RCTN：缩放裁剪、转 Tensor、归一化</span></span><br><span class="line">test_transform = transforms.Compose([transforms.Resize(<span class="number">256</span>),</span><br><span class="line">transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">transforms.ToTensor(),</span><br><span class="line">transforms.Normalize(</span><br><span class="line">mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>],</span><br><span class="line">std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">])</span><br></pre></td></tr></table></figure><blockquote><p>其中图像归一化处理中的<br><code>transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])</code>是CV界公认的，其中均值和标准差是利用很多的图片通过统计所计算出来的。</p></blockquote><h2 id="3-3、最终预测结果"><a href="#3-3、最终预测结果" class="headerlink" title="3.3、最终预测结果"></a>3.3、最终预测结果</h2><p><img src="https://s1.ax1x.com/2023/01/19/pS8Ygot.jpg" alt="预测结果"></p><h1 id="4、使用ImageNet预训练图像分类模型预测视频文件"><a href="#4、使用ImageNet预训练图像分类模型预测视频文件" class="headerlink" title="4、使用ImageNet预训练图像分类模型预测视频文件"></a>4、使用ImageNet预训练图像分类模型预测视频文件</h1><p>视频预测本质上与图像预测相似<br>步骤1：使用<code>mmcv</code>库将视频文件读取为一帧一帧的图像<br>步骤2：然后将这些图像通过预训练模型输出结果<br>步骤3：最后将结果通过<code>mmcv</code>库重新整合为视频文件输出</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>GitHub:<a href="https://github.com/TommyZihao/Train_Custom_Dataset">【子豪兄带你两天搞定AI毕业设计】</a><br>Bilibili:<a href="https://www.bilibili.com/video/BV1Jd4y1T7rw/?share_source=copy_web&vd_source=93b3233fa28ea39af3e78e2dcf5409c8">构建自己的图像分类数据集【两天搞定AI毕设】</a></p>]]>
        </content>
        
      
        <categories>
            
            <category> Pytorch预训练图像分类模型识别预测 </category>
            
        </categories>
        
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 图像分类 </tag>
            
            <tag> CV </tag>
            
        </tags>
        
    </entry>
    
    
    
    <entry>
        <title>「Task 1」构建自己的图像分类数据集</title>
        <link href="/posts/be3f2064.html" />
        <url>/posts/be3f2064.html</url>
        
        <content type="html">
            <![CDATA[<h1 id="1、如何获取图片数据集"><a href="#1、如何获取图片数据集" class="headerlink" title="1、如何获取图片数据集"></a>1、如何获取图片数据集</h1><ul><li>从网络上爬取图片</li><li>自己进行图片拍摄</li></ul><h1 id="2、制作图像分类数据集的注意事项"><a href="#2、制作图像分类数据集的注意事项" class="headerlink" title="2、制作图像分类数据集的注意事项"></a>2、制作图像分类数据集的注意事项</h1><ol><li>删除无关图像</li><li>类别均衡</li><li>多样性、代表性、一致性<blockquote><p>数据集应尽可能包括目标物体的各类场景，训练出的图像分类模型才能在各类测试场景中具备好的泛化性能，防止过拟合。<br>如：<br>不同拍摄环境（光照、设备、拍摄角度、遮挡、远近、大小）<br>不同形态（完整西瓜、切瓣西瓜、切块西瓜）<br>不同部位（全瓜、瓜皮、瓜瓤、瓜子）<br>不同时期（瓜秧、小瓜、大瓜）<br>不同背景（人物、菜地、抠图）<br>不同图像域（照片、漫画、剪贴画、油画）</p></blockquote></li></ol><blockquote><p>机器学习其实本质就像是我们人类学习一样，通过平时进行各种题型的练习，将所有题型都掌握了，那么考试也就手到擒来了。</p></blockquote><h1 id="3、数据集存储"><a href="#3、数据集存储" class="headerlink" title="3、数据集存储"></a>3、数据集存储</h1><p>将同一个图象类别的数据集放在同一个文件夹下，每个类别的图像数量相当</p><h1 id="4、删除异常图像"><a href="#4、删除异常图像" class="headerlink" title="4、删除异常图像"></a>4、删除异常图像</h1><p>删除cv读取异常的图像<br>删除非三通道的图像<br>删除文件夹下与图片无关的其他文件</p><h1 id="5、划分训练集和测试集"><a href="#5、划分训练集和测试集" class="headerlink" title="5、划分训练集和测试集"></a>5、划分训练集和测试集</h1><p>训练集与测试集划分常用比例：0.8:0.2、0.75:0.25<br>训练集图像数据放在train文件夹下<br>测试集图像数据放在val文件夹下</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>GitHub:<a href="https://github.com/TommyZihao/Train_Custom_Dataset">【子豪兄带你两天搞定AI毕业设计】</a><br>Bilibili:<a href="https://www.bilibili.com/video/BV1Jd4y1T7rw/?share_source=copy_web&vd_source=93b3233fa28ea39af3e78e2dcf5409c8">构建自己的图像分类数据集【两天搞定AI毕设】</a></p>]]>
        </content>
        
      
        <categories>
            
            <category> Pytorch预训练图像分类模型识别预测 </category>
            
        </categories>
        
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 图像分类 </tag>
            
            <tag> CV </tag>
            
        </tags>
        
    </entry>
    
    
    
    <entry>
        <title>Hello World</title>
        <link href="/posts/4a17b156.html" />
        <url>/posts/4a17b156.html</url>
        
        <content type="html">
            <![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]>
        </content>
        
      
        <categories>
            
            <category> demo </category>
            
        </categories>
        
      
    </entry>
    
    
    
    <entry>
        <title>第六章、树与二叉树</title>
        <link href="/posts/251bf008.html" />
        <url>/posts/251bf008.html</url>
        
        <content type="html">
            <![CDATA[<h1 id="树的基本概念"><a href="#树的基本概念" class="headerlink" title="树的基本概念"></a>树的基本概念</h1><h2 id="基本术语"><a href="#基本术语" class="headerlink" title="基本术语"></a>基本术语</h2><ul><li>度大于0的结点称为分支结点（又称非终端结点）；度为0的结点称为叶子结点（又称终端结点）</li><li>有序树和无序树：树中结点的各子树从左到右是有次序的，不能互换，称该树为有序树，否则称为无序树</li><li>结点的深度、高度和层次<blockquote><ol><li><strong>结点的层次</strong>从树根开始定义，根结点为第1层，它的子结点为第2层，以此类推。</li><li><strong>结点的深度</strong>是从<span style="font-family:default; font-size:default; color:red">根结点开始自顶向下</span>逐层累加的。</li><li><strong>结点的高度</strong>是从<span style="font-family:default; font-size:default; color:red">叶结点开始自底向上</span>逐层累加的。</li><li><strong>树的高度（或深度）</strong>是树中结点的最大层数</li></ol></blockquote></li></ul><h2 id="树的性质"><a href="#树的性质" class="headerlink" title="树的性质"></a>树的性质</h2><ul><li>树中的结点数等于所有结点的度数之和再加1 ⇒  $n&#x3D;\sum_{i&#x3D;1}^{m}(i\times n_i)+1&#x3D;n_0+n_1+\cdots+n_m$</li><li>度为m的树中第 $i$ 层上至多有 $m^{i-1}$个结点$（i \geq 1）$</li><li>高度为 $h$ 的 $m$ 叉树至多有$\frac{m^h-1}{m-1}$ 个结点（等比数列求和）</li><li>具有$n$个结点的 $m$ 叉树的最小高度为$\lceil log_m(n(m-1)+1) \rceil$<blockquote><p>推导：前 $h-1$ 层最多的结点数 ← $\frac{m^{h-1}-1}{m-1} \lt n \leq \frac{m^{h}-1}{m-1}$  → 前 $h$ 层最多的结点数<br>  得： $h_{min} &#x3D; \lceil log_m(n(m-1)+1) \rceil$</p></blockquote></li><li>高度为$h$的$m$叉树至少有 $h$ 个结点</li><li>高度为$h$、度为 $m$ 的树至少有 $h+m-1$ 个结点</li></ul><div class="CenterText">表1. 度为m的树与m叉树的区别</div><table><thead><tr><th>度为 $m$ 的树</th><th>$m$ 叉树</th></tr></thead><tbody><tr><td>任意结点的度$\leq m$</td><td>任意结点的度$\leq m$</td></tr><tr><td>至少有一个结点的度$&#x3D;m$</td><td>允许所有结点的度都$\lt m$</td></tr><tr><td>一定是非空树，至少有$m$个结点</td><td>可以是空树</td></tr><tr><td>子树是无序的</td><td>子树是有序的</td></tr></tbody></table><h1 id="二叉树的概念"><a href="#二叉树的概念" class="headerlink" title="二叉树的概念"></a>二叉树的概念</h1><h2 id="二叉树的定义"><a href="#二叉树的定义" class="headerlink" title="二叉树的定义"></a>二叉树的定义</h2><ul><li>二叉树是<strong>有序树</strong>，若将其左、右子树颠倒，则成为另一棵不同的二叉树。</li><li>二叉树与度为2的有序树的区别：<ol><li>度为2的树至少有3个结点，而二叉树可以为空。</li><li>度为2的有序树的孩子的左右次序是相对于另一孩子而言的，若某个结点只有一个孩子，则这个孩子就无须区分其左右次序，而二叉树无论其孩子数是否为2，均需确定其左右次序，即二叉树的结点次序不是相对于另一结点而言，而是确定的。</li></ol></li></ul><h2 id="特殊的二叉树"><a href="#特殊的二叉树" class="headerlink" title="特殊的二叉树"></a>特殊的二叉树</h2><ol><li>满二叉树。<ul><li>一棵高度为 $h$ ，且含有$2^h-1$个结点的二叉树称为满二叉树</li><li>满二叉树是特殊的完全二叉树</li></ul></li><li>完全二叉树。<ul><li>高度为$h$、有$n$个结点的二叉树，当且仅当其每个结点都与高度为$h$的满二叉树中编号为$1～n$的结点一一对应时，称为完全二叉树</li></ul></li></ol><h2 id="二叉树的性质"><a href="#二叉树的性质" class="headerlink" title="二叉树的性质"></a>二叉树的性质</h2><ul><li>$n_0&#x3D;n_2+1$</li><li>非空二叉树上第$k$层上至多有$2^{k-1}$个结点$（k\geq1）$</li><li>高度为$h$的二叉树至多有$2^{h}-1$个结点$（h\geq1）$</li><li>具有$n$个$（n\gt0）$结点的完全二叉树的高度为$\lceil log_2(n+1) \rceil$或$\lfloor log_2n \rfloor +1$</li></ul><h2 id="二叉树的存储结构"><a href="#二叉树的存储结构" class="headerlink" title="二叉树的存储结构"></a>二叉树的存储结构</h2><ol><li>顺序存储结构</li><li>链式存储结构</li></ol><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">BiTNode</span>&#123;</span><br><span class="line">ElemType data;                       <span class="comment">//数据域</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">BiTNode</span> *lchild,*rchild;      <span class="comment">//左、右孩子指针</span></span><br><span class="line">&#125;BiTNode,*BiTree;</span><br></pre></td></tr></table></figure><blockquote><p>在含有$n$个结点的二叉链表中，含有$n+1$个空链域。</p></blockquote><h1 id="二叉树的遍历和线索二叉树"><a href="#二叉树的遍历和线索二叉树" class="headerlink" title="二叉树的遍历和线索二叉树"></a>二叉树的遍历和线索二叉树</h1><h2 id="二叉树的遍历"><a href="#二叉树的遍历" class="headerlink" title="二叉树的遍历"></a>二叉树的遍历</h2><h3 id="先序遍历"><a href="#先序遍历" class="headerlink" title="先序遍历"></a>先序遍历</h3><h4 id="先序遍历递归算法"><a href="#先序遍历递归算法" class="headerlink" title="先序遍历递归算法"></a>先序遍历递归算法</h4><p>若二叉树非空：</p><ol><li>访问根结点。</li><li>先序遍历左子树。</li><li>先序遍历右子树。<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">//时间复杂度：𝑂(𝑛)</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">PreOrder</span><span class="params">(BiTree T)</span></span>&#123;</span><br><span class="line"><span class="keyword">if</span> (T != <span class="literal">NULL</span>)&#123;</span><br><span class="line"><span class="built_in">visit</span>(T);             <span class="comment">//访问根结点</span></span><br><span class="line"><span class="built_in">PreOrder</span>(T-&gt;lchild);   <span class="comment">//递归遍历左子树</span></span><br><span class="line"><span class="built_in">PreOrder</span>(T-&gt;rchild);   <span class="comment">//递归遍历右子树</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h4 id="先序遍历非递归算法"><a href="#先序遍历非递归算法" class="headerlink" title="先序遍历非递归算法"></a>先序遍历非递归算法</h4><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">PreOrder2</span><span class="params">(BiTree T)</span></span>&#123;</span><br><span class="line"><span class="built_in">InitStack</span>(S);</span><br><span class="line">BiTree p = T;</span><br><span class="line"><span class="keyword">while</span> (p || !<span class="built_in">IsEmpty</span>(S))&#123;</span><br><span class="line"><span class="keyword">if</span> (p)&#123;</span><br><span class="line"><span class="built_in">visit</span>(p);</span><br><span class="line"><span class="built_in">Push</span>(S, p);</span><br><span class="line">p = p-&gt;lchild;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span>&#123;</span><br><span class="line"><span class="built_in">Pop</span>(S, p);</span><br><span class="line">p = p-&gt;rchild;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="中序遍历"><a href="#中序遍历" class="headerlink" title="中序遍历"></a>中序遍历</h3><h4 id="中序遍历递归算法"><a href="#中序遍历递归算法" class="headerlink" title="中序遍历递归算法"></a>中序遍历递归算法</h4><p>若二叉树非空：</p><ol><li>中序遍历左子树。</li><li>访问根结点。</li><li>中序遍历右子树。<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">//时间复杂度：𝑂(𝑛)</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">InOrder</span><span class="params">(BiTree T)</span></span>&#123;</span><br><span class="line"><span class="keyword">if</span> (T != <span class="literal">NULL</span>)&#123;</span><br><span class="line"><span class="built_in">InOrder</span>(T-&gt;lchild);</span><br><span class="line"><span class="built_in">visit</span>(T);</span><br><span class="line"><span class="built_in">InOrder</span>(T-&gt;rchild);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h4 id="中序遍历非递归算法"><a href="#中序遍历非递归算法" class="headerlink" title="中序遍历非递归算法"></a>中序遍历非递归算法</h4><p>借助<strong>栈</strong>。算法思想：</p><ol><li>初始时依次扫描根结点的所有左侧结点并将他们一一进栈；</li><li>出栈一个结点，<strong>访问</strong>它；</li><li>扫描该结点的右孩子结点并将其进栈；</li><li>依次扫描右孩子结点的所有左侧结点，并一一进栈；</li><li>反复该过程直到栈空为止。</li></ol><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">InOrder2</span><span class="params">(BiTree T)</span></span>&#123;</span><br><span class="line"><span class="built_in">InitStack</span>(S);</span><br><span class="line">BiTree p = T;</span><br><span class="line"><span class="keyword">while</span> (p || !<span class="built_in">IsEmpty</span>(S))&#123;</span><br><span class="line"><span class="keyword">if</span> (p)&#123;</span><br><span class="line"><span class="built_in">Push</span>(S, p);</span><br><span class="line">p = p-&gt;lchild;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span>&#123;</span><br><span class="line"><span class="built_in">Pop</span>(S, p);</span><br><span class="line"><span class="built_in">visit</span>(p);</span><br><span class="line">p = p-&gt;rchild;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="后序遍历"><a href="#后序遍历" class="headerlink" title="后序遍历"></a>后序遍历</h3><h4 id="后序遍历递归算法"><a href="#后序遍历递归算法" class="headerlink" title="后序遍历递归算法"></a>后序遍历递归算法</h4><p>若二叉树非空：</p><ol><li>后序遍历左子树。</li><li>后序遍历右子树。</li><li>访问根结点。<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">//时间复杂度：𝑂(𝑛)</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">PostOrder</span><span class="params">(BiTree T)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (T != <span class="literal">NULL</span>)&#123;</span><br><span class="line">        <span class="built_in">PostOrder</span>(T-&gt;lchild);</span><br><span class="line">        <span class="built_in">PostOrder</span>(T-&gt;rchild);</span><br><span class="line">        <span class="built_in">visit</span>(T);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h4 id="后序遍历非递归算法"><a href="#后序遍历非递归算法" class="headerlink" title="后序遍历非递归算法"></a>后序遍历非递归算法</h4><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">算法思想：后序非递归遍历二叉树的顺序是先访问左子树，再访问右子树，最后访问根结点。当用堆栈来存储结点时，必须分清返回根结点时是从左子树返回的还是从右子树返回的。所以，使用辅助指针r，其指向最近访问过的结点。也可在结点中增加一个标志域，记录是否已被访问。</span></span><br><span class="line"><span class="comment">PS:访问一个结点*p时，栈中结点恰好是*p结点的所有祖先。从栈底到栈顶结点再加上*p结点，刚好构成从根结点到*p结点的一条路径。在很多算法设计中都利用了这一特性求解，如求根结点到某结点的路径、求两个结点的最近公共祖先等，都可以利用这个思路来实现。</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">postOrder</span><span class="params">(BiTree T)</span></span>&#123;</span><br><span class="line">    <span class="built_in">InitStack</span>(S);</span><br><span class="line">    BiTree p = T;</span><br><span class="line">    BiTree r = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="keyword">while</span>(p|| !<span class="built_in">IsEmpty</span>(S))&#123;</span><br><span class="line">        <span class="keyword">if</span>(p)&#123;   <span class="comment">//走到最左边</span></span><br><span class="line">           <span class="built_in">Push</span>(S,p);</span><br><span class="line">           p = p-&gt;lchild;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span>&#123;  <span class="comment">//向右</span></span><br><span class="line">            <span class="built_in">GetTop</span>(S,p);  <span class="comment">//取栈顶结点</span></span><br><span class="line">            <span class="keyword">if</span>(p-&gt;rchild &amp;&amp; p-&gt;rchild != r)&#123;  <span class="comment">//若右子树存在，且未被访问过</span></span><br><span class="line">                p = p-&gt;rchild;  <span class="comment">//转向右</span></span><br><span class="line">                <span class="built_in">push</span>(S,p);      <span class="comment">//压入栈</span></span><br><span class="line">                p = p-&gt;lchild;  <span class="comment">//再走到最左</span></span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;               <span class="comment">//否则，弹出结点并访问</span></span><br><span class="line">                <span class="built_in">Pop</span>(S,p);       <span class="comment">//将结点弹出</span></span><br><span class="line">                <span class="built_in">visit</span>(p);       <span class="comment">//访问该结点</span></span><br><span class="line">                r = p;          <span class="comment">//记录最近访问过的结点</span></span><br><span class="line">                p = <span class="literal">NULL</span>;       <span class="comment">//结点访问完后，重置该指针</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="comment">//else</span></span><br><span class="line">    &#125;<span class="comment">//while</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="层次遍历"><a href="#层次遍历" class="headerlink" title="层次遍历"></a>层次遍历</h3><p>借助<strong>队列</strong>。算法思想：</p><ol><li>初始将根入队并访问根结点；</li><li>若有左子树，则将左子树的根入队；</li><li>若有右子树，则将右子树的根入队；</li><li>然后出队，访问该结点；</li><li>反复该过程直到队空为止。</li></ol><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">levelOrder</span><span class="params">(BiTree T)</span></span>&#123;</span><br><span class="line">    <span class="built_in">InitQueue</span>(Q);</span><br><span class="line">    BiTree p;</span><br><span class="line">    <span class="built_in">EnQueue</span>(Q, T);</span><br><span class="line">    <span class="keyword">while</span> (!<span class="built_in">isEmpty</span>(Q))&#123;</span><br><span class="line">        <span class="built_in">DeQueue</span>(Q, p);</span><br><span class="line">        <span class="built_in">visit</span>(p);</span><br><span class="line">        <span class="keyword">if</span> (p-&gt;lchild != <span class="literal">NULL</span>)&#123;</span><br><span class="line">            <span class="built_in">EnQueue</span>(Q, p-&gt;lchild);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (p-&gt;rchild != <span class="literal">NULL</span>)&#123;</span><br><span class="line">            <span class="built_in">EnQueue</span>(Q, p-&gt;rchild);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="由遍历序列构造二叉树"><a href="#由遍历序列构造二叉树" class="headerlink" title="由遍历序列构造二叉树"></a>由遍历序列构造二叉树</h3><ul><li>先序（或后序）遍历序列+中序遍历序列可以确定一棵二叉树。</li><li>层次遍历序列+中序遍历序列也可以确定一棵二叉树。</li><li>而先序遍历序列+后序遍历序列不可以确定一颗二叉树。<ol><li>在先序序列中，第一个结点是根结点；</li><li>根结点将中序遍历序列划分为两部分；</li><li>然后在先序序列中确定两部分的结点，并且两部分的第一个结点分别为左子树的根结点和右子树的根结点；</li><li>在子树中递归重复该过程，边能唯一确定一棵二叉树。</li></ol></li></ul><h3 id="遍历序列相关"><a href="#遍历序列相关" class="headerlink" title="遍历序列相关"></a>遍历序列相关</h3><ol><li><p>一棵<span style="font-family:default; font-size:default; color:red">非空</span>二叉树的先序序列与中序序列相同：</p><ul><li>其所有非叶结点<span style="font-family:default; font-size:default; color:red">只有右子树</span></li></ul></li><li><p>一棵二叉树的先序序列与中序序列相反</p><ul><li>二叉树为空或只有一个结点</li><li>若二叉树<span style="font-family:default; font-size:default; color:red">不为空</span>，则任意结点<span style="font-family:default; font-size:default; color:red">没有右孩子</span></li></ul></li><li><p>一棵<span style="font-family:default; font-size:default; color:red">非空</span>二叉树的先序序列与后序序列相同</p><ul><li>只有一个根结点</li></ul></li><li><p>一棵<span style="font-family:default; font-size:default; color:red">非空</span>二叉树的先序序列与后序序列相反</p><ul><li>其任意结点均无左孩子或其任意结点均无右孩子</li><li>其只有一个叶子结点</li></ul></li></ol><h2 id="线索二叉树"><a href="#线索二叉树" class="headerlink" title="线索二叉树"></a>线索二叉树</h2><p>二叉树线索化后，仍然不能有效求解的问题是</p><ol><li><span style="font-family:default; font-size:default; color:red">后</span>序线索二叉树中求<span style="font-family:default; font-size:default; color:red">后序后继</span></li><li><span style="font-family:default; font-size:default; color:red">先</span>序线索二叉树中求<span style="font-family:default; font-size:default; color:red">先序前继</span></li></ol><h1 id="树、森林"><a href="#树、森林" class="headerlink" title="树、森林"></a>树、森林</h1><h2 id="树的存储结构"><a href="#树的存储结构" class="headerlink" title="树的存储结构"></a>树的存储结构</h2><h3 id="双亲表示法"><a href="#双亲表示法" class="headerlink" title="双亲表示法"></a>双亲表示法</h3><p>采用的一组连续的存储空间来存储每个节点。根节点没有双亲，所以其在数组中存储的值为-1。其余的节点，只需要存储其父节点对应的数组下标即可。</p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#defind MAX_TREE_SIZE 100 <span class="comment">//树中最多结点数</span></span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span>&#123; <span class="comment">//树的结点定义</span></span><br><span class="line">ElemType data; <span class="comment">//数据元素</span></span><br><span class="line"><span class="type">int</span> parent; <span class="comment">//双亲表示法</span></span><br><span class="line">&#125;PTNode;</span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span>&#123; <span class="comment">//树的类型定义</span></span><br><span class="line">PTNode nodes[MAX_TREE_SIZE]; <span class="comment">//双亲表示法</span></span><br><span class="line"><span class="type">int</span> n; <span class="comment">//结点数</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>![[Pasted image 20221102202519.png]]<br>![[Pasted image 20221102190431.png]]</p><h3 id="孩子表示法"><a href="#孩子表示法" class="headerlink" title="孩子表示法"></a>孩子表示法</h3><p>![[Pasted image 20221102190328.png]]</p><h3 id="孩子兄弟表示法"><a href="#孩子兄弟表示法" class="headerlink" title="孩子兄弟表示法"></a>孩子兄弟表示法</h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">CSNode</span>&#123;</span><br><span class="line">ElemType data; <span class="comment">//数据域</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">CSNode</span> *firstchild, *nextsibling; <span class="comment">//第一个孩子和右兄弟指针</span></span><br><span class="line">&#125;CSNode,*CSTree;</span><br></pre></td></tr></table></figure><p>![[Pasted image 20221102190534.png]]</p><h2 id="树和森林的遍历"><a href="#树和森林的遍历" class="headerlink" title="树和森林的遍历"></a>树和森林的遍历</h2><div class="CenterText">表2. 树和森林与二叉树遍历的对应关系</div><table><thead><tr><th>树</th><th>森林</th><th>二叉树</th></tr></thead><tbody><tr><td>先根遍历</td><td>先序遍历</td><td>先序遍历</td></tr><tr><td>后根遍历</td><td>中序遍历</td><td>中序遍历</td></tr></tbody></table><h1 id="树与二叉树的应用"><a href="#树与二叉树的应用" class="headerlink" title="树与二叉树的应用"></a>树与二叉树的应用</h1><h2 id="哈夫曼树和哈夫曼编码"><a href="#哈夫曼树和哈夫曼编码" class="headerlink" title="哈夫曼树和哈夫曼编码"></a>哈夫曼树和哈夫曼编码</h2><h3 id="哈夫曼树的定义"><a href="#哈夫曼树的定义" class="headerlink" title="哈夫曼树的定义"></a>哈夫曼树的定义</h3><p>给定 n 个权值作为 n 个叶子节点，构造一棵二叉树，若该树的带权路径长度（Weighted Path Length of Tree）达到最小， 称这样的二叉树为最优二叉树，也称为哈夫曼树（Huffman Tree）。<br><strong>带权路径长度（WPL）</strong>：<br>树中<span style="font-family:default; font-size:default; color:red">所有叶子结点的带权路径长度之和</span>称为该树的带权路径长度。<br>$$WPL&#x3D;\sum_{i&#x3D;1}^{n}w_i l_i$$</p><p>![[Pasted image 20221102203231.png]]</p><p class="CenterText">图. 哈夫曼树带权路径长度计算方法</p><h3 id="哈夫曼树的构造"><a href="#哈夫曼树的构造" class="headerlink" title="哈夫曼树的构造"></a>哈夫曼树的构造</h3><p><strong>基本步骤</strong>：</p><ol><li>从小到大进行排序, 将每一个数据，每个数据都是一个节点 ， 每个节点可以看成是一颗最简单的二叉树</li><li>取出根节点权值最小的两颗二叉树</li><li>组成一颗新的二叉树, 该新的二叉树的根节点的权值是前面两颗二叉树根节点权值的和</li><li>再将这颗新的二叉树，以根节点的权值大小 再次排序， 不断重复 1-2-3-4 的步骤，直到数列中，所有的数据都被处理，就得到一颗哈夫曼树</li></ol><h3 id="哈夫曼树的特点"><a href="#哈夫曼树的特点" class="headerlink" title="哈夫曼树的特点"></a>哈夫曼树的特点</h3><p>以二叉树为例</p><ol><li>WPL最小</li><li><span style="font-family:default; font-size:default; color:red">严格二叉树</span>（只有度为2的结点和度为0的结点）</li><li>若叶结点数为n，则总结点数为2n-1</li><li>具有n个叶结点的哈夫曼树<span style="font-family:default; font-size:default; color:red">不唯一</span><blockquote><p>注意：<span style="font-family:default; font-size:default; color:red">哈夫曼树不一定是二叉树</span>,也有可能有度为m的哈夫曼树,度为m的哈夫曼树只有度为m的结点和度为0的结点。</p></blockquote></li></ol>]]>
        </content>
        
      
      
        <tags>
            
            <tag> 考研 </tag>
            
            <tag> 数据结构 </tag>
            
        </tags>
        
    </entry>
    
    
  
  
</search>